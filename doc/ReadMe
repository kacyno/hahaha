V0.1
需求：
通过集群的方式将mysql中的海量数据（>500g）导入到hdfs中
为什么不用sqoop? 由于数据库的安全性，hadoop集群不允许开通mysql的权限，而重搭一个小型的hadoop集群作数据同步代价又太大

目标：
分布式的多机并发从mysql中导出数据到hdfs

各模块职责：
Client:
负责作业的提交，作业需要有sql及数据库用户名密码，连接串，分片字段等信息，
提交后Queen应该返回其为作业生成的唯一标识jobid,client提交作业后还应该根据需要时时获取作业的状态与进度

Queen:
#1.提供作业提交接口，接收client端的作业，并为之生成jobid,按作业信息将作业分为多个可并发的小任务
#2.接受Bee的注册，在有任务时将任务推给Bee执行，并监控整个作业的执行过程，当一个任务失败时应该有重试的容错机制，
同时可能的话也应有推测执行机制（即当一个任务明显慢于别人时，考虑在其它机器上并行执行）
#3.提供web监控界面，该监控应尽可能的使用websocket技术实时的显示作业的进度，同时也应能显示出一些出错信息

Bee:
#1.Bee内应以线程池的方式并发执行分给自己的任务，任务是Queen推送过来的，并应该将自己执行的进度周期性的汇报给Queen用于监控作业状态
#2.当Bee启动后向Queen注册，告诉Queen自己的任务接收数，queen在收到client端作业后应用推的方式将分成小片的任务推向bee


PS:

#1.通信使用akka框架

#2.开发语言为Java+Scala
